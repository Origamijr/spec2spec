{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"colab.ipynb","provenance":[{"file_id":"1vFnUMwETse3_sWDOzxYzvUEXb4EN9lml","timestamp":1591651657228}],"collapsed_sections":[],"authorship_tag":"ABX9TyOzS4yGzocHnwghiQ2XqZaw"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"pTgBSbD2cFBd","colab_type":"code","outputId":"e43e6485-98f7-4fe9-fcf7-ab63e4d3fc17","executionInfo":{"status":"ok","timestamp":1591829179530,"user_tz":420,"elapsed":20629,"user":{"displayName":"Kevin Huang","photoUrl":"","userId":"02407646057593863953"}},"colab":{"base_uri":"https://localhost:8080/","height":125}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"24lh51hUom1L","colab_type":"code","outputId":"c0f24e8f-fda7-4bb4-ca18-14b9e58d1315","executionInfo":{"status":"ok","timestamp":1591829179532,"user_tz":420,"elapsed":2359,"user":{"displayName":"Kevin Huang","photoUrl":"","userId":"02407646057593863953"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["%cd gdrive/'My Drive'/spec2spec"],"execution_count":3,"outputs":[{"output_type":"stream","text":["/content/gdrive/My Drive/spec2spec\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2wl6swKAoqvR","colab_type":"code","outputId":"23dcc8ac-e688-49dd-b46c-657c880a5679","executionInfo":{"status":"ok","timestamp":1591691337247,"user_tz":420,"elapsed":12191,"user":{"displayName":"Kevin Huang","photoUrl":"","userId":"02407646057593863953"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["#!git clone https://github.com/Origamijr/spec2spec.git\n","#!git pull"],"execution_count":0,"outputs":[{"output_type":"stream","text":["fatal: could not read Username for 'https://github.com': No such device or address\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RsBMy_SMpqxb","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"4bfe51e2-0bcd-4a84-8b66-0821d4c72c62","executionInfo":{"status":"ok","timestamp":1591829193863,"user_tz":420,"elapsed":13799,"user":{"displayName":"Kevin Huang","photoUrl":"","userId":"02407646057593863953"}}},"source":["!pip install -r requirements.txt"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: numpy==1.18.5 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 1)) (1.18.5)\n","Requirement already satisfied: matplotlib==3.2.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 2)) (3.2.1)\n","Requirement already satisfied: jupyter==1.0.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 3)) (1.0.0)\n","Requirement already satisfied: h5py==2.10.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 5)) (2.10.0)\n","Collecting librosa==0.7.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/77/b5/1817862d64a7c231afd15419d8418ae1f000742cac275e85c74b219cbccb/librosa-0.7.2.tar.gz (1.6MB)\n","\u001b[K     |████████████████████████████████| 1.6MB 12.0MB/s \n","\u001b[?25hRequirement already satisfied: Cython==0.29.19 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 8)) (0.29.19)\n","Obtaining pyworld from git+https://github.com/JeremyCCHsu/Python-Wrapper-for-World-Vocoder.git@a34a99980fc82825c0f2b616ea85069a4411cc94#egg=pyworld (from -r requirements.txt (line 9))\n","  Skipping because already up-to-date.\n","Requirement already satisfied: torch==1.5.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 11)) (1.5.0+cu101)\n","Requirement already satisfied: torchvision==0.6.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 12)) (0.6.0+cu101)\n","Collecting tensorboardX==2.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/35/f1/5843425495765c8c2dd0784a851a93ef204d314fc87bcc2bbb9f662a3ad1/tensorboardX-2.0-py2.py3-none-any.whl (195kB)\n","\u001b[K     |████████████████████████████████| 204kB 50.2MB/s \n","\u001b[?25hRequirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib==3.2.1->-r requirements.txt (line 2)) (2.4.7)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib==3.2.1->-r requirements.txt (line 2)) (2.8.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib==3.2.1->-r requirements.txt (line 2)) (1.2.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib==3.2.1->-r requirements.txt (line 2)) (0.10.0)\n","Requirement already satisfied: nbconvert in /usr/local/lib/python3.6/dist-packages (from jupyter==1.0.0->-r requirements.txt (line 3)) (5.6.1)\n","Requirement already satisfied: ipywidgets in /usr/local/lib/python3.6/dist-packages (from jupyter==1.0.0->-r requirements.txt (line 3)) (7.5.1)\n","Requirement already satisfied: ipykernel in /usr/local/lib/python3.6/dist-packages (from jupyter==1.0.0->-r requirements.txt (line 3)) (4.10.1)\n","Requirement already satisfied: jupyter-console in /usr/local/lib/python3.6/dist-packages (from jupyter==1.0.0->-r requirements.txt (line 3)) (5.2.0)\n","Requirement already satisfied: qtconsole in /usr/local/lib/python3.6/dist-packages (from jupyter==1.0.0->-r requirements.txt (line 3)) (4.7.4)\n","Requirement already satisfied: notebook in /usr/local/lib/python3.6/dist-packages (from jupyter==1.0.0->-r requirements.txt (line 3)) (5.2.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py==2.10.0->-r requirements.txt (line 5)) (1.12.0)\n","Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa==0.7.2->-r requirements.txt (line 6)) (2.1.8)\n","Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa==0.7.2->-r requirements.txt (line 6)) (1.4.1)\n","Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from librosa==0.7.2->-r requirements.txt (line 6)) (0.22.2.post1)\n","Requirement already satisfied: joblib>=0.12 in /usr/local/lib/python3.6/dist-packages (from librosa==0.7.2->-r requirements.txt (line 6)) (0.15.1)\n","Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa==0.7.2->-r requirements.txt (line 6)) (4.4.2)\n","Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from librosa==0.7.2->-r requirements.txt (line 6)) (0.2.2)\n","Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.6/dist-packages (from librosa==0.7.2->-r requirements.txt (line 6)) (0.48.0)\n","Collecting soundfile>=0.9.0\n","  Downloading https://files.pythonhosted.org/packages/eb/f2/3cbbbf3b96fb9fa91582c438b574cff3f45b29c772f94c400e2c99ef5db9/SoundFile-0.10.3.post1-py2.py3-none-any.whl\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==1.5.0->-r requirements.txt (line 11)) (0.16.0)\n","Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.6.0->-r requirements.txt (line 12)) (7.0.0)\n","Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX==2.0->-r requirements.txt (line 13)) (3.10.0)\n","Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter==1.0.0->-r requirements.txt (line 3)) (4.3.3)\n","Requirement already satisfied: nbformat>=4.4 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter==1.0.0->-r requirements.txt (line 3)) (5.0.6)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter==1.0.0->-r requirements.txt (line 3)) (2.1.3)\n","Requirement already satisfied: jinja2>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter==1.0.0->-r requirements.txt (line 3)) (2.11.2)\n","Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter==1.0.0->-r requirements.txt (line 3)) (1.4.2)\n","Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter==1.0.0->-r requirements.txt (line 3)) (3.1.5)\n","Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter==1.0.0->-r requirements.txt (line 3)) (0.4.4)\n","Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter==1.0.0->-r requirements.txt (line 3)) (0.6.0)\n","Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter==1.0.0->-r requirements.txt (line 3)) (0.8.4)\n","Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter==1.0.0->-r requirements.txt (line 3)) (0.3)\n","Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter==1.0.0->-r requirements.txt (line 3)) (4.6.3)\n","Requirement already satisfied: ipython>=4.0.0; python_version >= \"3.3\" in /usr/local/lib/python3.6/dist-packages (from ipywidgets->jupyter==1.0.0->-r requirements.txt (line 3)) (5.5.0)\n","Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets->jupyter==1.0.0->-r requirements.txt (line 3)) (3.5.1)\n","Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel->jupyter==1.0.0->-r requirements.txt (line 3)) (4.5.3)\n","Requirement already satisfied: jupyter-client in /usr/local/lib/python3.6/dist-packages (from ipykernel->jupyter==1.0.0->-r requirements.txt (line 3)) (5.3.4)\n","Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from jupyter-console->jupyter==1.0.0->-r requirements.txt (line 3)) (1.0.18)\n","Requirement already satisfied: pyzmq>=17.1 in /usr/local/lib/python3.6/dist-packages (from qtconsole->jupyter==1.0.0->-r requirements.txt (line 3)) (19.0.1)\n","Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from qtconsole->jupyter==1.0.0->-r requirements.txt (line 3)) (0.2.0)\n","Requirement already satisfied: qtpy in /usr/local/lib/python3.6/dist-packages (from qtconsole->jupyter==1.0.0->-r requirements.txt (line 3)) (1.9.0)\n","Requirement already satisfied: terminado>=0.3.3; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter==1.0.0->-r requirements.txt (line 3)) (0.8.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from numba>=0.43.0->librosa==0.7.2->-r requirements.txt (line 6)) (47.1.1)\n","Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba>=0.43.0->librosa==0.7.2->-r requirements.txt (line 6)) (0.31.0)\n","Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.6/dist-packages (from soundfile>=0.9.0->librosa==0.7.2->-r requirements.txt (line 6)) (1.14.0)\n","Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.4->nbconvert->jupyter==1.0.0->-r requirements.txt (line 3)) (2.6.0)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2>=2.4->nbconvert->jupyter==1.0.0->-r requirements.txt (line 3)) (1.1.1)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->jupyter==1.0.0->-r requirements.txt (line 3)) (0.5.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->jupyter==1.0.0->-r requirements.txt (line 3)) (20.4)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->jupyter==1.0.0->-r requirements.txt (line 3)) (0.7.5)\n","Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->jupyter==1.0.0->-r requirements.txt (line 3)) (0.8.1)\n","Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->jupyter==1.0.0->-r requirements.txt (line 3)) (4.8.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.0->jupyter-console->jupyter==1.0.0->-r requirements.txt (line 3)) (0.2.3)\n","Requirement already satisfied: ptyprocess; os_name != \"nt\" in /usr/local/lib/python3.6/dist-packages (from terminado>=0.3.3; sys_platform != \"win32\"->notebook->jupyter==1.0.0->-r requirements.txt (line 3)) (0.6.0)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi>=1.0->soundfile>=0.9.0->librosa==0.7.2->-r requirements.txt (line 6)) (2.20)\n","Building wheels for collected packages: librosa\n","  Building wheel for librosa (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for librosa: filename=librosa-0.7.2-cp36-none-any.whl size=1612885 sha256=e369fd8d3654fcbf56bd972f1c3e89f5aa379ddfa0fcd5d9c7850cf45e654ab9\n","  Stored in directory: /root/.cache/pip/wheels/4c/6e/d7/bb93911540d2d1e44d690a1561871e5b6af82b69e80938abef\n","Successfully built librosa\n","Installing collected packages: soundfile, librosa, pyworld, tensorboardX\n","  Found existing installation: librosa 0.6.3\n","    Uninstalling librosa-0.6.3:\n","      Successfully uninstalled librosa-0.6.3\n","  Running setup.py develop for pyworld\n","Successfully installed librosa-0.7.2 pyworld soundfile-0.10.3.post1 tensorboardX-2.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Xz2xgcu4qoKJ","colab_type":"code","outputId":"f840b470-d61d-4317-d285-0f23baf81d5d","executionInfo":{"status":"ok","timestamp":1591829197686,"user_tz":420,"elapsed":15447,"user":{"displayName":"Kevin Huang","photoUrl":"","userId":"02407646057593863953"}},"colab":{"base_uri":"https://localhost:8080/","height":336}},"source":["import torch\n","print(torch.cuda.is_available())\n","\n","!nvidia-smi"],"execution_count":5,"outputs":[{"output_type":"stream","text":["True\n","Wed Jun 10 22:46:38 2020       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 440.82       Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|===============================+======================+======================|\n","|   0  Tesla P4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   35C    P8     7W /  75W |     10MiB /  7611MiB |      0%      Default |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                       GPU Memory |\n","|  GPU       PID   Type   Process name                             Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"DQPkVGRtqPwk","colab_type":"code","outputId":"ca4f418e-14fa-4dcd-8898-292724f1ae10","executionInfo":{"status":"ok","timestamp":1591850489298,"user_tz":420,"elapsed":4304924,"user":{"displayName":"Kevin Huang","photoUrl":"","userId":"02407646057593863953"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["!python train.py"],"execution_count":52,"outputs":[{"output_type":"stream","text":["Test 22\n","paired 1-1.hdf5 and 1-1.hdf5\n","paired 1-10.hdf5 and 1-10.hdf5\n","paired 1-11.hdf5 and 1-11.hdf5\n","paired 1-12.hdf5 and 1-12.hdf5\n","paired 1-13.hdf5 and 1-13.hdf5\n","paired 1-14.hdf5 and 1-14.hdf5\n","paired 1-15.hdf5 and 1-15.hdf5\n","paired 1-16.hdf5 and 1-16.hdf5\n","paired 1-17.hdf5 and 1-17.hdf5\n","paired 1-18.hdf5 and 1-18.hdf5\n","paired 1-2.hdf5 and 1-2.hdf5\n","paired 1-3.hdf5 and 1-3.hdf5\n","paired 1-4.hdf5 and 1-4.hdf5\n","paired 1-5.hdf5 and 1-5.hdf5\n","paired 1-6.hdf5 and 1-6.hdf5\n","paired 1-7.hdf5 and 1-7.hdf5\n","paired 1-8.hdf5 and 1-8.hdf5\n","paired 1-9.hdf5 and 1-9.hdf5\n","Using cuda:0\n","06/11/2020 03:30:05 - INFO - __main__ -   TRAIN: Batch 0/63, loss_G_GAN   -0.0944, loss_G_L1   73.9647, loss_G   73.8703, loss_D_GAN    0.0379, loss_D 1481.2860\n","06/11/2020 03:30:32 - INFO - __main__ -   TRAIN: Batch 10/63, loss_G_GAN   -0.0174, loss_G_L1   38.7199, loss_G   38.7025, loss_D_GAN   -0.0008, loss_D    3.7525\n","06/11/2020 03:31:00 - INFO - __main__ -   TRAIN: Batch 20/63, loss_G_GAN   -0.0085, loss_G_L1   33.7213, loss_G   33.7128, loss_D_GAN   -0.0003, loss_D    1.1683\n","06/11/2020 03:31:27 - INFO - __main__ -   TRAIN: Batch 30/63, loss_G_GAN   -0.0073, loss_G_L1   26.3759, loss_G   26.3686, loss_D_GAN   -0.0001, loss_D    0.6988\n","06/11/2020 03:31:55 - INFO - __main__ -   TRAIN: Batch 40/63, loss_G_GAN   -0.0180, loss_G_L1   23.8074, loss_G   23.7894, loss_D_GAN    0.0001, loss_D    1.7583\n","06/11/2020 03:32:22 - INFO - __main__ -   TRAIN: Batch 50/63, loss_G_GAN   -0.0085, loss_G_L1   21.6435, loss_G   21.6350, loss_D_GAN    0.0001, loss_D    0.8467\n","06/11/2020 03:32:50 - INFO - __main__ -   TRAIN: Batch 60/63, loss_G_GAN   -0.0180, loss_G_L1   20.3613, loss_G   20.3433, loss_D_GAN   -0.0002, loss_D    0.3989\n","06/11/2020 03:32:58 - INFO - __main__ -   TRAIN: Epoch 0/41, loss_G_GAN   -0.0204, loss_G_L1   31.6142, loss_G   31.5938, loss_D_GAN    0.0003, loss_D   45.3791\n","/content/gdrive/My Drive/spec2spec/datasets.py:92: RuntimeWarning: overflow encountered in exp\n","  result = np.exp(data / scale - shift) - 1e-6\n","/content/gdrive/My Drive/spec2spec/test.py:28: RuntimeWarning: overflow encountered in true_divide\n","  fake = (fake - fake_min) / (fake_max - fake_min)\n","06/11/2020 03:32:59 - INFO - root -   Summary name FAKE TRAIN epoch 0 ~ min: 0.000000 max: 0.000000 is illegal; using FAKE_TRAIN_epoch_0___min__0.000000_max__0.000000 instead.\n","/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py:90: RuntimeWarning: overflow encountered in reduce\n","  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n","06/11/2020 03:32:59 - WARNING - root -   NaN or Inf found in input tensor.\n","/usr/local/lib/python3.6/dist-packages/tensorboardX/summary.py:276: RuntimeWarning: overflow encountered in multiply\n","  tensor = (tensor * 255.0).astype(np.uint8)\n","06/11/2020 03:32:59 - INFO - root -   Summary name REAL TRAIN epoch 0 ~ min: 0.000000 max: 0.112207 is illegal; using REAL_TRAIN_epoch_0___min__0.000000_max__0.112207 instead.\n","06/11/2020 03:33:01 - INFO - __main__ -   VALID: Batch 0/63, loss_G_GAN   -0.0071, loss_G_L1   18.6336, loss_G   18.6264, loss_D_GAN    0.2931, loss_D    0.2932\n","06/11/2020 03:33:08 - INFO - __main__ -   VALID: Batch 10/63, loss_G_GAN   -0.0103, loss_G_L1   19.6819, loss_G   19.6715, loss_D_GAN    3.0622, loss_D    3.0625\n","06/11/2020 03:33:12 - INFO - __main__ -   VALID: Epoch 0/41, loss_G_GAN   -0.0075, loss_G_L1   19.5593, loss_G   19.5518, loss_D_GAN    0.5821, loss_D    0.5822\n","06/11/2020 03:33:13 - INFO - root -   Summary name FAKE VALID epoch 0 ~ min: 0.000000 max: 0.000000 is illegal; using FAKE_VALID_epoch_0___min__0.000000_max__0.000000 instead.\n","06/11/2020 03:33:13 - WARNING - root -   NaN or Inf found in input tensor.\n","06/11/2020 03:33:13 - INFO - root -   Summary name REAL VALID epoch 0 ~ min: 0.000000 max: 0.118774 is illegal; using REAL_VALID_epoch_0___min__0.000000_max__0.118774 instead.\n","06/11/2020 03:33:16 - INFO - __main__ -   TRAIN: Batch 0/63, loss_G_GAN   -0.0076, loss_G_L1   19.4553, loss_G   19.4476, loss_D_GAN   -0.0001, loss_D    0.3564\n","06/11/2020 03:33:44 - INFO - __main__ -   TRAIN: Batch 10/63, loss_G_GAN   -0.0094, loss_G_L1   19.4733, loss_G   19.4639, loss_D_GAN    0.0000, loss_D    0.3268\n","06/11/2020 03:34:11 - INFO - __main__ -   TRAIN: Batch 20/63, loss_G_GAN   -0.0112, loss_G_L1   19.8483, loss_G   19.8371, loss_D_GAN   -0.0001, loss_D    0.1154\n","06/11/2020 03:34:39 - INFO - __main__ -   TRAIN: Batch 30/63, loss_G_GAN   -0.0138, loss_G_L1   17.2260, loss_G   17.2122, loss_D_GAN   -0.0000, loss_D    0.1598\n","06/11/2020 03:35:07 - INFO - __main__ -   TRAIN: Batch 40/63, loss_G_GAN   -0.0104, loss_G_L1   15.0962, loss_G   15.0858, loss_D_GAN    0.0001, loss_D    0.2596\n","06/11/2020 03:35:35 - INFO - __main__ -   TRAIN: Batch 50/63, loss_G_GAN    0.0010, loss_G_L1   17.6444, loss_G   17.6454, loss_D_GAN   -0.0002, loss_D    0.9336\n","06/11/2020 03:36:03 - INFO - __main__ -   TRAIN: Batch 60/63, loss_G_GAN   -0.0177, loss_G_L1   15.1766, loss_G   15.1589, loss_D_GAN   -0.0000, loss_D    0.1003\n","06/11/2020 03:36:11 - INFO - __main__ -   TRAIN: Epoch 1/41, loss_G_GAN   -0.0096, loss_G_L1   16.6047, loss_G   16.5951, loss_D_GAN   -0.0000, loss_D    0.3044\n","06/11/2020 03:36:12 - INFO - __main__ -   VALID: Batch 0/63, loss_G_GAN    0.0634, loss_G_L1   14.6930, loss_G   14.7565, loss_D_GAN    4.6175, loss_D    4.6165\n","06/11/2020 03:36:20 - INFO - __main__ -   VALID: Batch 10/63, loss_G_GAN    0.0739, loss_G_L1   14.1979, loss_G   14.2718, loss_D_GAN    0.1402, loss_D    0.1402\n","06/11/2020 03:36:24 - INFO - __main__ -   VALID: Epoch 1/41, loss_G_GAN    0.0688, loss_G_L1   14.4738, loss_G   14.5426, loss_D_GAN    0.7403, loss_D    0.7402\n","06/11/2020 03:36:27 - INFO - __main__ -   TRAIN: Batch 0/63, loss_G_GAN    0.0651, loss_G_L1   14.1376, loss_G   14.2026, loss_D_GAN    0.0000, loss_D    0.2406\n","06/11/2020 03:36:55 - INFO - __main__ -   TRAIN: Batch 10/63, loss_G_GAN   -0.0226, loss_G_L1   12.8402, loss_G   12.8177, loss_D_GAN    0.0000, loss_D    0.0740\n","06/11/2020 03:37:23 - INFO - __main__ -   TRAIN: Batch 20/63, loss_G_GAN   -0.0035, loss_G_L1   13.0680, loss_G   13.0645, loss_D_GAN    0.0003, loss_D    0.2180\n","06/11/2020 03:37:51 - INFO - __main__ -   TRAIN: Batch 30/63, loss_G_GAN   -0.0005, loss_G_L1   15.0433, loss_G   15.0428, loss_D_GAN   -0.0000, loss_D    0.7649\n","06/11/2020 03:38:18 - INFO - __main__ -   TRAIN: Batch 40/63, loss_G_GAN    0.0168, loss_G_L1   12.1578, loss_G   12.1747, loss_D_GAN    0.0000, loss_D    0.0714\n","06/11/2020 03:38:46 - INFO - __main__ -   TRAIN: Batch 50/63, loss_G_GAN    0.0612, loss_G_L1   12.4466, loss_G   12.5078, loss_D_GAN    0.0003, loss_D    1.2798\n","06/11/2020 03:39:14 - INFO - __main__ -   TRAIN: Batch 60/63, loss_G_GAN   -0.0204, loss_G_L1   11.0173, loss_G   10.9969, loss_D_GAN   -0.0000, loss_D    0.0767\n","06/11/2020 03:39:23 - INFO - __main__ -   TRAIN: Epoch 2/41, loss_G_GAN   -0.0121, loss_G_L1   12.6632, loss_G   12.6511, loss_D_GAN   -0.0000, loss_D    0.2067\n","06/11/2020 03:39:23 - INFO - __main__ -   VALID: Batch 0/63, loss_G_GAN   -0.0203, loss_G_L1   12.1966, loss_G   12.1763, loss_D_GAN    0.0858, loss_D    0.0859\n","06/11/2020 03:39:31 - INFO - __main__ -   VALID: Batch 10/63, loss_G_GAN   -0.0204, loss_G_L1   11.8548, loss_G   11.8344, loss_D_GAN    0.1244, loss_D    0.1244\n","06/11/2020 03:39:35 - INFO - __main__ -   VALID: Epoch 2/41, loss_G_GAN   -0.0204, loss_G_L1   12.2736, loss_G   12.2532, loss_D_GAN    1.5095, loss_D    1.5097\n","06/11/2020 03:39:38 - INFO - __main__ -   TRAIN: Batch 0/63, loss_G_GAN   -0.0187, loss_G_L1   11.9479, loss_G   11.9293, loss_D_GAN   -0.0000, loss_D    0.0693\n","06/11/2020 03:40:06 - INFO - __main__ -   TRAIN: Batch 10/63, loss_G_GAN   -0.0440, loss_G_L1   10.2964, loss_G   10.2524, loss_D_GAN    0.0000, loss_D    0.0404\n","06/11/2020 03:40:34 - INFO - __main__ -   TRAIN: Batch 20/63, loss_G_GAN   -0.0196, loss_G_L1    9.9634, loss_G    9.9438, loss_D_GAN   -0.0000, loss_D    0.0384\n","06/11/2020 03:41:02 - INFO - __main__ -   TRAIN: Batch 30/63, loss_G_GAN   -0.1454, loss_G_L1   10.3324, loss_G   10.1870, loss_D_GAN   -0.0000, loss_D    1.1287\n","06/11/2020 03:41:30 - INFO - __main__ -   TRAIN: Batch 40/63, loss_G_GAN   -0.0043, loss_G_L1    9.5423, loss_G    9.5380, loss_D_GAN   -0.0001, loss_D    0.3842\n","06/11/2020 03:41:58 - INFO - __main__ -   TRAIN: Batch 50/63, loss_G_GAN    0.0502, loss_G_L1    9.0239, loss_G    9.0741, loss_D_GAN    0.0000, loss_D    0.1476\n","06/11/2020 03:42:26 - INFO - __main__ -   TRAIN: Batch 60/63, loss_G_GAN    0.0151, loss_G_L1    8.7776, loss_G    8.7928, loss_D_GAN   -0.0001, loss_D    0.3453\n","06/11/2020 03:42:34 - INFO - __main__ -   TRAIN: Epoch 3/41, loss_G_GAN   -0.0195, loss_G_L1   10.0681, loss_G   10.0486, loss_D_GAN    0.0000, loss_D    0.6286\n","06/11/2020 03:42:35 - INFO - __main__ -   VALID: Batch 0/63, loss_G_GAN   -0.0201, loss_G_L1    9.8593, loss_G    9.8392, loss_D_GAN    0.1631, loss_D    0.1632\n","06/11/2020 03:42:43 - INFO - __main__ -   VALID: Batch 10/63, loss_G_GAN   -0.0210, loss_G_L1    9.2300, loss_G    9.2090, loss_D_GAN    0.0862, loss_D    0.0862\n","06/11/2020 03:42:47 - INFO - __main__ -   VALID: Epoch 3/41, loss_G_GAN   -0.0202, loss_G_L1    9.3956, loss_G    9.3754, loss_D_GAN    1.6440, loss_D    1.6440\n","06/11/2020 03:42:49 - INFO - __main__ -   TRAIN: Batch 0/63, loss_G_GAN   -0.0308, loss_G_L1    9.3977, loss_G    9.3668, loss_D_GAN   -0.0000, loss_D    0.1100\n","06/11/2020 03:43:17 - INFO - __main__ -   TRAIN: Batch 10/63, loss_G_GAN    0.0295, loss_G_L1    8.4046, loss_G    8.4342, loss_D_GAN    0.0000, loss_D    0.0968\n","06/11/2020 03:43:45 - INFO - __main__ -   TRAIN: Batch 20/63, loss_G_GAN   -0.1395, loss_G_L1    7.7994, loss_G    7.6598, loss_D_GAN    0.0000, loss_D    0.1218\n","06/11/2020 03:44:13 - INFO - __main__ -   TRAIN: Batch 30/63, loss_G_GAN   -0.0341, loss_G_L1    8.3716, loss_G    8.3375, loss_D_GAN    0.0000, loss_D    0.0315\n","06/11/2020 03:44:41 - INFO - __main__ -   TRAIN: Batch 40/63, loss_G_GAN   -0.0020, loss_G_L1    8.5006, loss_G    8.4987, loss_D_GAN    0.0001, loss_D    0.0818\n","06/11/2020 03:45:09 - INFO - __main__ -   TRAIN: Batch 50/63, loss_G_GAN   -0.0103, loss_G_L1    7.7308, loss_G    7.7204, loss_D_GAN    0.0000, loss_D    0.0020\n","06/11/2020 03:45:37 - INFO - __main__ -   TRAIN: Batch 60/63, loss_G_GAN   -0.0100, loss_G_L1   10.2609, loss_G   10.2509, loss_D_GAN    0.0000, loss_D    0.0046\n","06/11/2020 03:45:46 - INFO - __main__ -   TRAIN: Epoch 4/41, loss_G_GAN   -0.0207, loss_G_L1    8.4616, loss_G    8.4408, loss_D_GAN   -0.0000, loss_D    0.3423\n","06/11/2020 03:45:46 - INFO - __main__ -   VALID: Batch 0/63, loss_G_GAN   -0.0119, loss_G_L1    7.7272, loss_G    7.7153, loss_D_GAN    0.0015, loss_D    0.0015\n","06/11/2020 03:45:54 - INFO - __main__ -   VALID: Batch 10/63, loss_G_GAN   -0.0121, loss_G_L1    8.7137, loss_G    8.7016, loss_D_GAN    0.0305, loss_D    0.0304\n","06/11/2020 03:45:58 - INFO - __main__ -   VALID: Epoch 4/41, loss_G_GAN   -0.0117, loss_G_L1    7.9727, loss_G    7.9610, loss_D_GAN    0.0192, loss_D    0.0192\n","06/11/2020 03:46:01 - INFO - __main__ -   TRAIN: Batch 0/63, loss_G_GAN   -0.0130, loss_G_L1    9.5599, loss_G    9.5468, loss_D_GAN    0.0000, loss_D    0.1300\n","06/11/2020 03:46:29 - INFO - __main__ -   TRAIN: Batch 10/63, loss_G_GAN   -0.0147, loss_G_L1    6.9983, loss_G    6.9836, loss_D_GAN   -0.0000, loss_D    0.0028\n","06/11/2020 03:46:57 - INFO - __main__ -   TRAIN: Batch 20/63, loss_G_GAN   -0.0155, loss_G_L1    7.3327, loss_G    7.3172, loss_D_GAN   -0.0000, loss_D    0.0025\n","06/11/2020 03:47:25 - INFO - __main__ -   TRAIN: Batch 30/63, loss_G_GAN   -0.0202, loss_G_L1    7.3104, loss_G    7.2902, loss_D_GAN   -0.0002, loss_D    0.0180\n","06/11/2020 03:47:53 - INFO - __main__ -   TRAIN: Batch 40/63, loss_G_GAN   -0.0183, loss_G_L1    6.8426, loss_G    6.8244, loss_D_GAN    0.0000, loss_D    0.0023\n","06/11/2020 03:48:21 - INFO - __main__ -   TRAIN: Batch 50/63, loss_G_GAN   -0.0176, loss_G_L1    7.4396, loss_G    7.4221, loss_D_GAN   -0.0000, loss_D    0.0071\n","06/11/2020 03:48:49 - INFO - __main__ -   TRAIN: Batch 60/63, loss_G_GAN    0.0001, loss_G_L1    6.3604, loss_G    6.3604, loss_D_GAN   -0.0000, loss_D    0.0019\n","06/11/2020 03:48:57 - INFO - __main__ -   TRAIN: Epoch 5/41, loss_G_GAN   -0.0096, loss_G_L1    7.3310, loss_G    7.3215, loss_D_GAN   -0.0000, loss_D    0.0149\n","06/11/2020 03:48:58 - INFO - __main__ -   VALID: Batch 0/63, loss_G_GAN   -0.0032, loss_G_L1    6.7203, loss_G    6.7171, loss_D_GAN    0.0023, loss_D    0.0023\n","06/11/2020 03:49:06 - INFO - __main__ -   VALID: Batch 10/63, loss_G_GAN   -0.0038, loss_G_L1    6.6936, loss_G    6.6897, loss_D_GAN    0.0050, loss_D    0.0050\n","06/11/2020 03:49:10 - INFO - __main__ -   VALID: Epoch 5/41, loss_G_GAN   -0.0040, loss_G_L1    7.1099, loss_G    7.1059, loss_D_GAN    0.0148, loss_D    0.0148\n","06/11/2020 03:49:12 - INFO - __main__ -   TRAIN: Batch 0/63, loss_G_GAN   -0.0038, loss_G_L1    6.6730, loss_G    6.6692, loss_D_GAN    0.0000, loss_D    0.0001\n","06/11/2020 03:49:40 - INFO - __main__ -   TRAIN: Batch 10/63, loss_G_GAN   -0.0117, loss_G_L1    6.5835, loss_G    6.5718, loss_D_GAN    0.0000, loss_D    0.0083\n","06/11/2020 03:50:08 - INFO - __main__ -   TRAIN: Batch 20/63, loss_G_GAN   -0.0120, loss_G_L1    6.4913, loss_G    6.4793, loss_D_GAN    0.0000, loss_D    0.0015\n","06/11/2020 03:50:36 - INFO - __main__ -   TRAIN: Batch 30/63, loss_G_GAN   -0.0151, loss_G_L1    5.4828, loss_G    5.4677, loss_D_GAN   -0.0000, loss_D    0.0061\n","06/11/2020 03:51:04 - INFO - __main__ -   TRAIN: Batch 40/63, loss_G_GAN   -0.0105, loss_G_L1    5.4250, loss_G    5.4145, loss_D_GAN   -0.0000, loss_D    0.0000\n","06/11/2020 03:51:32 - INFO - __main__ -   TRAIN: Batch 50/63, loss_G_GAN   -0.0232, loss_G_L1    6.2085, loss_G    6.1854, loss_D_GAN   -0.0001, loss_D    0.0167\n","06/11/2020 03:52:00 - INFO - __main__ -   TRAIN: Batch 60/63, loss_G_GAN   -0.0089, loss_G_L1    5.5211, loss_G    5.5122, loss_D_GAN   -0.0000, loss_D    0.0187\n","06/11/2020 03:52:09 - INFO - __main__ -   TRAIN: Epoch 6/41, loss_G_GAN   -0.0099, loss_G_L1    6.2451, loss_G    6.2352, loss_D_GAN    0.0000, loss_D    0.0119\n","06/11/2020 03:52:09 - INFO - __main__ -   VALID: Batch 0/63, loss_G_GAN   -0.0173, loss_G_L1    5.2277, loss_G    5.2105, loss_D_GAN    0.0017, loss_D    0.0017\n","06/11/2020 03:52:17 - INFO - __main__ -   VALID: Batch 10/63, loss_G_GAN   -0.0174, loss_G_L1    5.1314, loss_G    5.1141, loss_D_GAN    0.0000, loss_D    0.0000\n","06/11/2020 03:52:21 - INFO - __main__ -   VALID: Epoch 6/41, loss_G_GAN   -0.0173, loss_G_L1    5.3894, loss_G    5.3721, loss_D_GAN    0.0108, loss_D    0.0108\n","06/11/2020 03:52:24 - INFO - __main__ -   TRAIN: Batch 0/63, loss_G_GAN   -0.0138, loss_G_L1    5.1341, loss_G    5.1204, loss_D_GAN   -0.0000, loss_D    0.0064\n","06/11/2020 03:52:52 - INFO - __main__ -   TRAIN: Batch 10/63, loss_G_GAN   -0.0091, loss_G_L1    5.2158, loss_G    5.2067, loss_D_GAN    0.0000, loss_D    0.0009\n","06/11/2020 03:53:20 - INFO - __main__ -   TRAIN: Batch 20/63, loss_G_GAN   -0.0157, loss_G_L1    5.3232, loss_G    5.3074, loss_D_GAN   -0.0000, loss_D    0.0105\n","06/11/2020 03:53:48 - INFO - __main__ -   TRAIN: Batch 30/63, loss_G_GAN   -0.0137, loss_G_L1    7.7327, loss_G    7.7191, loss_D_GAN    0.0000, loss_D    0.0039\n","06/11/2020 03:54:16 - INFO - __main__ -   TRAIN: Batch 40/63, loss_G_GAN   -0.0093, loss_G_L1    6.8649, loss_G    6.8556, loss_D_GAN   -0.0000, loss_D    0.0016\n","06/11/2020 03:54:44 - INFO - __main__ -   TRAIN: Batch 50/63, loss_G_GAN   -0.0087, loss_G_L1    5.4886, loss_G    5.4799, loss_D_GAN    0.0000, loss_D    0.0032\n","06/11/2020 03:55:11 - INFO - __main__ -   TRAIN: Batch 60/63, loss_G_GAN    0.0119, loss_G_L1    5.3896, loss_G    5.4016, loss_D_GAN   -0.0000, loss_D    0.0018\n","06/11/2020 03:55:20 - INFO - __main__ -   TRAIN: Epoch 7/41, loss_G_GAN   -0.0090, loss_G_L1    6.1321, loss_G    6.1231, loss_D_GAN   -0.0000, loss_D    0.0078\n","06/11/2020 03:55:21 - INFO - __main__ -   VALID: Batch 0/63, loss_G_GAN    0.0014, loss_G_L1    6.5664, loss_G    6.5678, loss_D_GAN    0.0153, loss_D    0.0153\n","06/11/2020 03:55:28 - INFO - __main__ -   VALID: Batch 10/63, loss_G_GAN    0.0058, loss_G_L1    5.6476, loss_G    5.6534, loss_D_GAN    0.0030, loss_D    0.0030\n","06/11/2020 03:55:32 - INFO - __main__ -   VALID: Epoch 7/41, loss_G_GAN    0.0043, loss_G_L1    5.9260, loss_G    5.9303, loss_D_GAN    0.0088, loss_D    0.0088\n","06/11/2020 03:55:35 - INFO - __main__ -   TRAIN: Batch 0/63, loss_G_GAN   -0.0013, loss_G_L1    5.9293, loss_G    5.9280, loss_D_GAN   -0.0000, loss_D    0.0049\n","06/11/2020 03:56:03 - INFO - __main__ -   TRAIN: Batch 10/63, loss_G_GAN   -0.0090, loss_G_L1    5.0878, loss_G    5.0788, loss_D_GAN    0.0000, loss_D    0.0030\n","06/11/2020 03:56:31 - INFO - __main__ -   TRAIN: Batch 20/63, loss_G_GAN   -0.0108, loss_G_L1    5.5986, loss_G    5.5878, loss_D_GAN   -0.0000, loss_D    0.0043\n","06/11/2020 03:56:59 - INFO - __main__ -   TRAIN: Batch 30/63, loss_G_GAN   -0.0166, loss_G_L1    5.0110, loss_G    4.9945, loss_D_GAN   -0.0000, loss_D    0.0044\n","06/11/2020 03:57:27 - INFO - __main__ -   TRAIN: Batch 40/63, loss_G_GAN   -0.0045, loss_G_L1    5.0236, loss_G    5.0191, loss_D_GAN   -0.0000, loss_D    0.0001\n","06/11/2020 03:57:55 - INFO - __main__ -   TRAIN: Batch 50/63, loss_G_GAN   -0.0154, loss_G_L1    8.4788, loss_G    8.4633, loss_D_GAN    0.0000, loss_D    0.0049\n","06/11/2020 03:58:23 - INFO - __main__ -   TRAIN: Batch 60/63, loss_G_GAN   -0.0106, loss_G_L1    4.9535, loss_G    4.9429, loss_D_GAN    0.0000, loss_D    0.0005\n","06/11/2020 03:58:31 - INFO - __main__ -   TRAIN: Epoch 8/41, loss_G_GAN   -0.0102, loss_G_L1    5.4271, loss_G    5.4170, loss_D_GAN   -0.0000, loss_D    0.0066\n","06/11/2020 03:58:32 - INFO - __main__ -   VALID: Batch 0/63, loss_G_GAN   -0.0136, loss_G_L1    5.2552, loss_G    5.2416, loss_D_GAN   -0.0000, loss_D    0.0000\n","06/11/2020 03:58:40 - INFO - __main__ -   VALID: Batch 10/63, loss_G_GAN   -0.0136, loss_G_L1    5.0308, loss_G    5.0172, loss_D_GAN    0.0013, loss_D    0.0013\n","06/11/2020 03:58:44 - INFO - __main__ -   VALID: Epoch 8/41, loss_G_GAN   -0.0138, loss_G_L1    5.3353, loss_G    5.3215, loss_D_GAN    0.0072, loss_D    0.0072\n","06/11/2020 03:58:46 - INFO - __main__ -   TRAIN: Batch 0/63, loss_G_GAN   -0.0145, loss_G_L1    4.6044, loss_G    4.5899, loss_D_GAN   -0.0000, loss_D    0.0003\n","06/11/2020 03:59:14 - INFO - __main__ -   TRAIN: Batch 10/63, loss_G_GAN   -0.0162, loss_G_L1    4.6594, loss_G    4.6432, loss_D_GAN   -0.0000, loss_D    0.0000\n","06/11/2020 03:59:42 - INFO - __main__ -   TRAIN: Batch 20/63, loss_G_GAN    0.0003, loss_G_L1    4.5900, loss_G    4.5903, loss_D_GAN   -0.0000, loss_D    0.0003\n","06/11/2020 04:00:10 - INFO - __main__ -   TRAIN: Batch 30/63, loss_G_GAN   -0.0178, loss_G_L1    4.6327, loss_G    4.6149, loss_D_GAN   -0.0000, loss_D    0.0006\n","06/11/2020 04:00:38 - INFO - __main__ -   TRAIN: Batch 40/63, loss_G_GAN   -0.0091, loss_G_L1    5.5361, loss_G    5.5270, loss_D_GAN    0.0000, loss_D    0.0096\n","06/11/2020 04:01:06 - INFO - __main__ -   TRAIN: Batch 50/63, loss_G_GAN   -0.0028, loss_G_L1    5.9570, loss_G    5.9541, loss_D_GAN   -0.0000, loss_D    0.0833\n","06/11/2020 04:01:34 - INFO - __main__ -   TRAIN: Batch 60/63, loss_G_GAN   -0.0125, loss_G_L1    4.2415, loss_G    4.2289, loss_D_GAN   -0.0000, loss_D    0.0018\n","06/11/2020 04:01:42 - INFO - __main__ -   TRAIN: Epoch 9/41, loss_G_GAN   -0.0106, loss_G_L1    4.8674, loss_G    4.8568, loss_D_GAN   -0.0000, loss_D    0.0056\n","06/11/2020 04:01:43 - INFO - __main__ -   VALID: Batch 0/63, loss_G_GAN   -0.0128, loss_G_L1    4.4942, loss_G    4.4814, loss_D_GAN    0.0044, loss_D    0.0044\n","06/11/2020 04:01:51 - INFO - __main__ -   VALID: Batch 10/63, loss_G_GAN   -0.0121, loss_G_L1    5.0216, loss_G    5.0094, loss_D_GAN    0.0044, loss_D    0.0044\n","06/11/2020 04:01:55 - INFO - __main__ -   VALID: Epoch 9/41, loss_G_GAN   -0.0130, loss_G_L1    4.5514, loss_G    4.5384, loss_D_GAN    0.0068, loss_D    0.0068\n","06/11/2020 04:01:58 - INFO - __main__ -   TRAIN: Batch 0/63, loss_G_GAN   -0.0130, loss_G_L1    4.3691, loss_G    4.3561, loss_D_GAN   -0.0000, loss_D    0.0007\n","06/11/2020 04:02:26 - INFO - __main__ -   TRAIN: Batch 10/63, loss_G_GAN   -0.0113, loss_G_L1    4.9746, loss_G    4.9633, loss_D_GAN   -0.0000, loss_D    0.0001\n","06/11/2020 04:02:54 - INFO - __main__ -   TRAIN: Batch 20/63, loss_G_GAN   -0.0087, loss_G_L1    5.3352, loss_G    5.3266, loss_D_GAN    0.0000, loss_D    0.0079\n","06/11/2020 04:03:22 - INFO - __main__ -   TRAIN: Batch 30/63, loss_G_GAN   -0.0221, loss_G_L1    3.9670, loss_G    3.9449, loss_D_GAN    0.0000, loss_D    0.0012\n","06/11/2020 04:03:50 - INFO - __main__ -   TRAIN: Batch 40/63, loss_G_GAN   -0.0168, loss_G_L1    3.9620, loss_G    3.9452, loss_D_GAN    0.0000, loss_D    0.0000\n","06/11/2020 04:04:17 - INFO - __main__ -   TRAIN: Batch 50/63, loss_G_GAN   -0.0132, loss_G_L1    4.0712, loss_G    4.0580, loss_D_GAN   -0.0000, loss_D    0.0004\n","06/11/2020 04:04:45 - INFO - __main__ -   TRAIN: Batch 60/63, loss_G_GAN   -0.0018, loss_G_L1    4.0760, loss_G    4.0743, loss_D_GAN   -0.0000, loss_D    0.0002\n","06/11/2020 04:04:54 - INFO - __main__ -   TRAIN: Epoch 10/41, loss_G_GAN   -0.0113, loss_G_L1    4.5968, loss_G    4.5855, loss_D_GAN   -0.0000, loss_D    0.0047\n","06/11/2020 04:04:55 - INFO - root -   Summary name FAKE TRAIN epoch 10 ~ min: 0.000000 max: 0.000000 is illegal; using FAKE_TRAIN_epoch_10___min__0.000000_max__0.000000 instead.\n","06/11/2020 04:04:55 - WARNING - root -   NaN or Inf found in input tensor.\n","06/11/2020 04:04:55 - INFO - root -   Summary name REAL TRAIN epoch 10 ~ min: 0.000000 max: 0.087384 is illegal; using REAL_TRAIN_epoch_10___min__0.000000_max__0.087384 instead.\n","06/11/2020 04:04:56 - INFO - __main__ -   VALID: Batch 0/63, loss_G_GAN   -0.0056, loss_G_L1    4.2807, loss_G    4.2752, loss_D_GAN    0.0088, loss_D    0.0088\n","06/11/2020 04:05:04 - INFO - __main__ -   VALID: Batch 10/63, loss_G_GAN   -0.0068, loss_G_L1    5.0752, loss_G    5.0684, loss_D_GAN    0.0066, loss_D    0.0066\n","06/11/2020 04:05:08 - INFO - __main__ -   VALID: Epoch 10/41, loss_G_GAN   -0.0052, loss_G_L1    4.4268, loss_G    4.4216, loss_D_GAN    0.0096, loss_D    0.0096\n","06/11/2020 04:05:08 - INFO - root -   Summary name FAKE VALID epoch 10 ~ min: 0.000000 max: 0.000000 is illegal; using FAKE_VALID_epoch_10___min__0.000000_max__0.000000 instead.\n","06/11/2020 04:05:08 - WARNING - root -   NaN or Inf found in input tensor.\n","06/11/2020 04:05:08 - INFO - root -   Summary name REAL VALID epoch 10 ~ min: 0.000000 max: 0.109074 is illegal; using REAL_VALID_epoch_10___min__0.000000_max__0.109074 instead.\n","06/11/2020 04:05:12 - INFO - __main__ -   TRAIN: Batch 0/63, loss_G_GAN   -0.0066, loss_G_L1    4.0352, loss_G    4.0287, loss_D_GAN    0.0000, loss_D    0.0000\n","06/11/2020 04:05:40 - INFO - __main__ -   TRAIN: Batch 10/63, loss_G_GAN   -0.0058, loss_G_L1    3.8823, loss_G    3.8765, loss_D_GAN   -0.0000, loss_D    0.0030\n","06/11/2020 04:06:08 - INFO - __main__ -   TRAIN: Batch 20/63, loss_G_GAN   -0.0145, loss_G_L1    4.3528, loss_G    4.3384, loss_D_GAN    0.0000, loss_D    0.0125\n","06/11/2020 04:06:36 - INFO - __main__ -   TRAIN: Batch 30/63, loss_G_GAN   -0.0132, loss_G_L1    3.8368, loss_G    3.8236, loss_D_GAN    0.0000, loss_D    0.0323\n","06/11/2020 04:07:04 - INFO - __main__ -   TRAIN: Batch 40/63, loss_G_GAN   -0.0157, loss_G_L1    4.1237, loss_G    4.1080, loss_D_GAN    0.0000, loss_D    0.0000\n","06/11/2020 04:07:32 - INFO - __main__ -   TRAIN: Batch 50/63, loss_G_GAN   -0.0172, loss_G_L1    3.4379, loss_G    3.4207, loss_D_GAN    0.0000, loss_D    0.0012\n","06/11/2020 04:08:00 - INFO - __main__ -   TRAIN: Batch 60/63, loss_G_GAN    0.0000, loss_G_L1    4.1712, loss_G    4.1712, loss_D_GAN    0.0000, loss_D    0.0007\n","06/11/2020 04:08:08 - INFO - __main__ -   TRAIN: Epoch 11/41, loss_G_GAN   -0.0119, loss_G_L1    3.9652, loss_G    3.9533, loss_D_GAN   -0.0000, loss_D    0.0044\n","06/11/2020 04:08:09 - INFO - __main__ -   VALID: Batch 0/63, loss_G_GAN   -0.0079, loss_G_L1    3.9808, loss_G    3.9729, loss_D_GAN    0.0057, loss_D    0.0057\n","06/11/2020 04:08:17 - INFO - __main__ -   VALID: Batch 10/63, loss_G_GAN   -0.0058, loss_G_L1    3.2540, loss_G    3.2482, loss_D_GAN    0.0078, loss_D    0.0078\n","06/11/2020 04:08:20 - INFO - __main__ -   VALID: Epoch 11/41, loss_G_GAN   -0.0063, loss_G_L1    3.6752, loss_G    3.6689, loss_D_GAN    0.0125, loss_D    0.0125\n","06/11/2020 04:08:23 - INFO - __main__ -   TRAIN: Batch 0/63, loss_G_GAN   -0.0091, loss_G_L1    3.6547, loss_G    3.6456, loss_D_GAN    0.0000, loss_D    0.0009\n","06/11/2020 04:08:51 - INFO - __main__ -   TRAIN: Batch 10/63, loss_G_GAN   -0.0159, loss_G_L1    3.3558, loss_G    3.3399, loss_D_GAN    0.0000, loss_D    0.0000\n","06/11/2020 04:09:19 - INFO - __main__ -   TRAIN: Batch 20/63, loss_G_GAN   -0.0026, loss_G_L1    4.1633, loss_G    4.1607, loss_D_GAN    0.0000, loss_D    0.0639\n","06/11/2020 04:09:47 - INFO - __main__ -   TRAIN: Batch 30/63, loss_G_GAN   -0.0085, loss_G_L1    3.2577, loss_G    3.2493, loss_D_GAN   -0.0000, loss_D    0.0002\n","06/11/2020 04:10:15 - INFO - __main__ -   TRAIN: Batch 40/63, loss_G_GAN   -0.0084, loss_G_L1    3.3348, loss_G    3.3264, loss_D_GAN    0.0000, loss_D    0.0299\n","06/11/2020 04:10:43 - INFO - __main__ -   TRAIN: Batch 50/63, loss_G_GAN   -0.0352, loss_G_L1    3.7413, loss_G    3.7061, loss_D_GAN    0.0000, loss_D    0.0157\n","06/11/2020 04:11:11 - INFO - __main__ -   TRAIN: Batch 60/63, loss_G_GAN   -0.0105, loss_G_L1    3.5370, loss_G    3.5264, loss_D_GAN   -0.0000, loss_D    0.0000\n","06/11/2020 04:11:19 - INFO - __main__ -   TRAIN: Epoch 12/41, loss_G_GAN   -0.0143, loss_G_L1    3.5936, loss_G    3.5793, loss_D_GAN   -0.0000, loss_D    0.0042\n","06/11/2020 04:11:20 - INFO - __main__ -   VALID: Batch 0/63, loss_G_GAN   -0.0133, loss_G_L1    3.2616, loss_G    3.2484, loss_D_GAN    0.0005, loss_D    0.0005\n","06/11/2020 04:11:28 - INFO - __main__ -   VALID: Batch 10/63, loss_G_GAN   -0.0134, loss_G_L1    3.3086, loss_G    3.2952, loss_D_GAN    0.0054, loss_D    0.0054\n","06/11/2020 04:11:32 - INFO - __main__ -   VALID: Epoch 12/41, loss_G_GAN   -0.0134, loss_G_L1    3.5411, loss_G    3.5277, loss_D_GAN    0.0096, loss_D    0.0096\n","06/11/2020 04:11:35 - INFO - __main__ -   TRAIN: Batch 0/63, loss_G_GAN   -0.0132, loss_G_L1    3.6009, loss_G    3.5877, loss_D_GAN    0.0000, loss_D    0.0274\n","06/11/2020 04:12:03 - INFO - __main__ -   TRAIN: Batch 10/63, loss_G_GAN   -0.0154, loss_G_L1    3.7433, loss_G    3.7279, loss_D_GAN    0.0000, loss_D    0.0018\n","06/11/2020 04:12:31 - INFO - __main__ -   TRAIN: Batch 20/63, loss_G_GAN   -0.0201, loss_G_L1    3.4113, loss_G    3.3912, loss_D_GAN    0.0000, loss_D    0.0096\n","06/11/2020 04:12:59 - INFO - __main__ -   TRAIN: Batch 30/63, loss_G_GAN    0.0074, loss_G_L1    2.8406, loss_G    2.8480, loss_D_GAN    0.0000, loss_D    0.0011\n","06/11/2020 04:13:26 - INFO - __main__ -   TRAIN: Batch 40/63, loss_G_GAN   -0.0113, loss_G_L1    2.9949, loss_G    2.9835, loss_D_GAN    0.0000, loss_D    0.0015\n","06/11/2020 04:13:54 - INFO - __main__ -   TRAIN: Batch 50/63, loss_G_GAN   -0.0134, loss_G_L1    3.2192, loss_G    3.2057, loss_D_GAN    0.0000, loss_D    0.0020\n","06/11/2020 04:14:22 - INFO - __main__ -   TRAIN: Batch 60/63, loss_G_GAN   -0.0068, loss_G_L1    3.5079, loss_G    3.5011, loss_D_GAN    0.0000, loss_D    0.0125\n","06/11/2020 04:14:31 - INFO - __main__ -   TRAIN: Epoch 13/41, loss_G_GAN   -0.0099, loss_G_L1    3.3006, loss_G    3.2906, loss_D_GAN    0.0000, loss_D    0.0038\n","06/11/2020 04:14:32 - INFO - __main__ -   VALID: Batch 0/63, loss_G_GAN   -0.0084, loss_G_L1    3.9251, loss_G    3.9167, loss_D_GAN    0.0023, loss_D    0.0023\n","06/11/2020 04:14:39 - INFO - __main__ -   VALID: Batch 10/63, loss_G_GAN   -0.0070, loss_G_L1    4.0348, loss_G    4.0278, loss_D_GAN    0.0048, loss_D    0.0048\n","06/11/2020 04:14:43 - INFO - __main__ -   VALID: Epoch 13/41, loss_G_GAN   -0.0075, loss_G_L1    4.2677, loss_G    4.2602, loss_D_GAN    0.0229, loss_D    0.0229\n","06/11/2020 04:14:46 - INFO - __main__ -   TRAIN: Batch 0/63, loss_G_GAN   -0.0085, loss_G_L1    4.1146, loss_G    4.1060, loss_D_GAN    0.0000, loss_D    0.0001\n","06/11/2020 04:15:14 - INFO - __main__ -   TRAIN: Batch 10/63, loss_G_GAN   -0.0091, loss_G_L1    3.0352, loss_G    3.0261, loss_D_GAN    0.0000, loss_D    0.0011\n","06/11/2020 04:15:42 - INFO - __main__ -   TRAIN: Batch 20/63, loss_G_GAN   -0.0137, loss_G_L1    3.1175, loss_G    3.1038, loss_D_GAN   -0.0000, loss_D    0.0001\n","06/11/2020 04:16:10 - INFO - __main__ -   TRAIN: Batch 30/63, loss_G_GAN   -0.0156, loss_G_L1    3.3309, loss_G    3.3153, loss_D_GAN   -0.0000, loss_D    0.0006\n","06/11/2020 04:16:38 - INFO - __main__ -   TRAIN: Batch 40/63, loss_G_GAN   -0.0160, loss_G_L1    3.3329, loss_G    3.3169, loss_D_GAN   -0.0000, loss_D    0.0029\n","06/11/2020 04:17:06 - INFO - __main__ -   TRAIN: Batch 50/63, loss_G_GAN    0.0162, loss_G_L1    2.6656, loss_G    2.6818, loss_D_GAN   -0.0000, loss_D    0.0003\n","06/11/2020 04:17:34 - INFO - __main__ -   TRAIN: Batch 60/63, loss_G_GAN   -0.0116, loss_G_L1    2.9278, loss_G    2.9162, loss_D_GAN    0.0000, loss_D    0.0175\n","06/11/2020 04:17:42 - INFO - __main__ -   TRAIN: Epoch 14/41, loss_G_GAN   -0.0118, loss_G_L1    3.1040, loss_G    3.0922, loss_D_GAN   -0.0000, loss_D    0.0037\n","06/11/2020 04:17:43 - INFO - __main__ -   VALID: Batch 0/63, loss_G_GAN    0.0044, loss_G_L1    2.9348, loss_G    2.9392, loss_D_GAN    0.0014, loss_D    0.0014\n","06/11/2020 04:17:51 - INFO - __main__ -   VALID: Batch 10/63, loss_G_GAN    0.0044, loss_G_L1    3.7164, loss_G    3.7208, loss_D_GAN    0.0102, loss_D    0.0102\n","06/11/2020 04:17:55 - INFO - __main__ -   VALID: Epoch 14/41, loss_G_GAN    0.0036, loss_G_L1    3.0759, loss_G    3.0795, loss_D_GAN    0.0337, loss_D    0.0337\n","06/11/2020 04:17:57 - INFO - __main__ -   TRAIN: Batch 0/63, loss_G_GAN   -0.0254, loss_G_L1    2.8201, loss_G    2.7947, loss_D_GAN   -0.0000, loss_D    0.0122\n","06/11/2020 04:18:25 - INFO - __main__ -   TRAIN: Batch 10/63, loss_G_GAN   -0.0232, loss_G_L1    2.8963, loss_G    2.8731, loss_D_GAN   -0.0000, loss_D    0.0046\n","06/11/2020 04:18:53 - INFO - __main__ -   TRAIN: Batch 20/63, loss_G_GAN   -0.0245, loss_G_L1    3.2704, loss_G    3.2458, loss_D_GAN    0.0000, loss_D    0.0037\n","06/11/2020 04:19:21 - INFO - __main__ -   TRAIN: Batch 30/63, loss_G_GAN    0.0747, loss_G_L1    3.7004, loss_G    3.7752, loss_D_GAN   -0.0000, loss_D    0.0060\n","06/11/2020 04:19:49 - INFO - __main__ -   TRAIN: Batch 40/63, loss_G_GAN   -0.0191, loss_G_L1    2.5096, loss_G    2.4905, loss_D_GAN    0.0000, loss_D    0.0000\n","06/11/2020 04:20:17 - INFO - __main__ -   TRAIN: Batch 50/63, loss_G_GAN   -0.0051, loss_G_L1    3.8367, loss_G    3.8316, loss_D_GAN    0.0000, loss_D    0.0119\n","06/11/2020 04:20:45 - INFO - __main__ -   TRAIN: Batch 60/63, loss_G_GAN   -0.0276, loss_G_L1    2.5695, loss_G    2.5419, loss_D_GAN   -0.0000, loss_D    0.0004\n","06/11/2020 04:20:53 - INFO - __main__ -   TRAIN: Epoch 15/41, loss_G_GAN   -0.0146, loss_G_L1    3.0256, loss_G    3.0110, loss_D_GAN    0.0000, loss_D    0.0048\n","06/11/2020 04:20:54 - INFO - __main__ -   VALID: Batch 0/63, loss_G_GAN   -0.0315, loss_G_L1    2.8159, loss_G    2.7845, loss_D_GAN    0.0095, loss_D    0.0095\n","06/11/2020 04:21:02 - INFO - __main__ -   VALID: Batch 10/63, loss_G_GAN   -0.0335, loss_G_L1    3.2811, loss_G    3.2477, loss_D_GAN    0.0031, loss_D    0.0031\n","06/11/2020 04:21:06 - INFO - __main__ -   VALID: Epoch 15/41, loss_G_GAN   -0.0322, loss_G_L1    3.2195, loss_G    3.1872, loss_D_GAN    0.0113, loss_D    0.0113\n","06/11/2020 04:21:09 - INFO - __main__ -   TRAIN: Batch 0/63, loss_G_GAN   -0.0321, loss_G_L1    3.1943, loss_G    3.1621, loss_D_GAN    0.0000, loss_D    0.0002\n","06/11/2020 04:21:37 - INFO - __main__ -   TRAIN: Batch 10/63, loss_G_GAN   -0.0300, loss_G_L1    2.5502, loss_G    2.5202, loss_D_GAN   -0.0000, loss_D    0.0016\n","06/11/2020 04:22:05 - INFO - __main__ -   TRAIN: Batch 20/63, loss_G_GAN   -0.0043, loss_G_L1    2.5672, loss_G    2.5629, loss_D_GAN   -0.0000, loss_D    0.0004\n","06/11/2020 04:22:33 - INFO - __main__ -   TRAIN: Batch 30/63, loss_G_GAN   -0.0204, loss_G_L1    2.5041, loss_G    2.4837, loss_D_GAN    0.0000, loss_D    0.0010\n","06/11/2020 04:23:01 - INFO - __main__ -   TRAIN: Batch 40/63, loss_G_GAN    0.0188, loss_G_L1    2.6368, loss_G    2.6555, loss_D_GAN   -0.0000, loss_D    0.0046\n","06/11/2020 04:23:29 - INFO - __main__ -   TRAIN: Batch 50/63, loss_G_GAN   -0.0136, loss_G_L1    2.9171, loss_G    2.9035, loss_D_GAN    0.0000, loss_D    0.0016\n","06/11/2020 04:23:57 - INFO - __main__ -   TRAIN: Batch 60/63, loss_G_GAN   -0.0086, loss_G_L1    2.6286, loss_G    2.6200, loss_D_GAN    0.0000, loss_D    0.0001\n","06/11/2020 04:24:05 - INFO - __main__ -   TRAIN: Epoch 16/41, loss_G_GAN   -0.0119, loss_G_L1    2.8427, loss_G    2.8308, loss_D_GAN    0.0000, loss_D    0.0029\n","06/11/2020 04:24:06 - INFO - __main__ -   VALID: Batch 0/63, loss_G_GAN   -0.0129, loss_G_L1    2.5924, loss_G    2.5795, loss_D_GAN    0.0267, loss_D    0.0267\n","06/11/2020 04:24:14 - INFO - __main__ -   VALID: Batch 10/63, loss_G_GAN   -0.0129, loss_G_L1    3.0716, loss_G    3.0587, loss_D_GAN    0.0377, loss_D    0.0377\n","06/11/2020 04:24:17 - INFO - __main__ -   VALID: Epoch 16/41, loss_G_GAN   -0.0124, loss_G_L1    2.7851, loss_G    2.7727, loss_D_GAN    0.0060, loss_D    0.0060\n","06/11/2020 04:24:20 - INFO - __main__ -   TRAIN: Batch 0/63, loss_G_GAN   -0.0121, loss_G_L1    2.7630, loss_G    2.7509, loss_D_GAN    0.0000, loss_D    0.0000\n","06/11/2020 04:24:48 - INFO - __main__ -   TRAIN: Batch 10/63, loss_G_GAN   -0.0094, loss_G_L1    2.4743, loss_G    2.4649, loss_D_GAN    0.0000, loss_D    0.0004\n","06/11/2020 04:25:16 - INFO - __main__ -   TRAIN: Batch 20/63, loss_G_GAN   -0.0147, loss_G_L1    2.8543, loss_G    2.8396, loss_D_GAN   -0.0000, loss_D    0.0001\n","06/11/2020 04:25:44 - INFO - __main__ -   TRAIN: Batch 30/63, loss_G_GAN   -0.0196, loss_G_L1    2.2730, loss_G    2.2534, loss_D_GAN    0.0000, loss_D    0.0013\n","06/11/2020 04:26:12 - INFO - __main__ -   TRAIN: Batch 40/63, loss_G_GAN   -0.0126, loss_G_L1    3.0005, loss_G    2.9878, loss_D_GAN    0.0000, loss_D    0.0001\n","06/11/2020 04:26:40 - INFO - __main__ -   TRAIN: Batch 50/63, loss_G_GAN   -0.0048, loss_G_L1    2.1428, loss_G    2.1381, loss_D_GAN    0.0000, loss_D    0.0001\n","06/11/2020 04:27:08 - INFO - __main__ -   TRAIN: Batch 60/63, loss_G_GAN   -0.0200, loss_G_L1    2.8694, loss_G    2.8494, loss_D_GAN   -0.0000, loss_D    0.0010\n","06/11/2020 04:27:16 - INFO - __main__ -   TRAIN: Epoch 17/41, loss_G_GAN   -0.0149, loss_G_L1    2.5742, loss_G    2.5592, loss_D_GAN    0.0000, loss_D    0.0027\n","06/11/2020 04:27:17 - INFO - __main__ -   VALID: Batch 0/63, loss_G_GAN   -0.0202, loss_G_L1    2.6637, loss_G    2.6435, loss_D_GAN    0.0040, loss_D    0.0040\n","06/11/2020 04:27:25 - INFO - __main__ -   VALID: Batch 10/63, loss_G_GAN   -0.0204, loss_G_L1    3.0038, loss_G    2.9834, loss_D_GAN    0.0070, loss_D    0.0070\n","06/11/2020 04:27:29 - INFO - __main__ -   VALID: Epoch 17/41, loss_G_GAN   -0.0199, loss_G_L1    2.9080, loss_G    2.8881, loss_D_GAN    0.0108, loss_D    0.0108\n","06/11/2020 04:27:32 - INFO - __main__ -   TRAIN: Batch 0/63, loss_G_GAN   -0.0202, loss_G_L1    2.6565, loss_G    2.6363, loss_D_GAN   -0.0000, loss_D    0.0000\n","06/11/2020 04:28:00 - INFO - __main__ -   TRAIN: Batch 10/63, loss_G_GAN   -0.0190, loss_G_L1    2.5767, loss_G    2.5576, loss_D_GAN    0.0000, loss_D    0.0015\n","06/11/2020 04:28:27 - INFO - __main__ -   TRAIN: Batch 20/63, loss_G_GAN   -0.0151, loss_G_L1    2.8280, loss_G    2.8129, loss_D_GAN   -0.0000, loss_D    0.0077\n","06/11/2020 04:28:55 - INFO - __main__ -   TRAIN: Batch 30/63, loss_G_GAN   -0.0131, loss_G_L1    3.0861, loss_G    3.0731, loss_D_GAN    0.0000, loss_D    0.0087\n","06/11/2020 04:29:23 - INFO - __main__ -   TRAIN: Batch 40/63, loss_G_GAN    0.0138, loss_G_L1    2.3865, loss_G    2.4003, loss_D_GAN   -0.0000, loss_D    0.0000\n","06/11/2020 04:29:51 - INFO - __main__ -   TRAIN: Batch 50/63, loss_G_GAN   -0.0213, loss_G_L1    2.5092, loss_G    2.4880, loss_D_GAN    0.0000, loss_D    0.0002\n","06/11/2020 04:30:19 - INFO - __main__ -   TRAIN: Batch 60/63, loss_G_GAN   -0.0122, loss_G_L1    3.1995, loss_G    3.1873, loss_D_GAN    0.0000, loss_D    0.0002\n","06/11/2020 04:30:28 - INFO - __main__ -   TRAIN: Epoch 18/41, loss_G_GAN   -0.0130, loss_G_L1    2.4556, loss_G    2.4427, loss_D_GAN    0.0000, loss_D    0.0027\n","06/11/2020 04:30:28 - INFO - __main__ -   VALID: Batch 0/63, loss_G_GAN   -0.0111, loss_G_L1    2.7655, loss_G    2.7544, loss_D_GAN    0.0182, loss_D    0.0182\n","06/11/2020 04:30:36 - INFO - __main__ -   VALID: Batch 10/63, loss_G_GAN   -0.0091, loss_G_L1    2.6747, loss_G    2.6655, loss_D_GAN    0.0005, loss_D    0.0005\n","06/11/2020 04:30:40 - INFO - __main__ -   VALID: Epoch 18/41, loss_G_GAN   -0.0104, loss_G_L1    2.5322, loss_G    2.5218, loss_D_GAN    0.0071, loss_D    0.0071\n","06/11/2020 04:30:43 - INFO - __main__ -   TRAIN: Batch 0/63, loss_G_GAN   -0.0084, loss_G_L1    2.3778, loss_G    2.3694, loss_D_GAN   -0.0000, loss_D    0.0008\n","06/11/2020 04:31:11 - INFO - __main__ -   TRAIN: Batch 10/63, loss_G_GAN   -0.0125, loss_G_L1    2.3919, loss_G    2.3794, loss_D_GAN    0.0000, loss_D    0.0001\n","06/11/2020 04:31:39 - INFO - __main__ -   TRAIN: Batch 20/63, loss_G_GAN   -0.0169, loss_G_L1    2.3162, loss_G    2.2994, loss_D_GAN   -0.0000, loss_D    0.0000\n","06/11/2020 04:32:07 - INFO - __main__ -   TRAIN: Batch 30/63, loss_G_GAN   -0.0050, loss_G_L1    2.3338, loss_G    2.3288, loss_D_GAN    0.0000, loss_D    0.0007\n","06/11/2020 04:32:35 - INFO - __main__ -   TRAIN: Batch 40/63, loss_G_GAN   -0.0115, loss_G_L1    2.1685, loss_G    2.1570, loss_D_GAN   -0.0000, loss_D    0.0013\n","06/11/2020 04:33:03 - INFO - __main__ -   TRAIN: Batch 50/63, loss_G_GAN   -0.0137, loss_G_L1    2.6590, loss_G    2.6453, loss_D_GAN   -0.0000, loss_D    0.0002\n","06/11/2020 04:33:31 - INFO - __main__ -   TRAIN: Batch 60/63, loss_G_GAN   -0.0075, loss_G_L1    2.6218, loss_G    2.6144, loss_D_GAN   -0.0000, loss_D    0.0000\n","06/11/2020 04:33:39 - INFO - __main__ -   TRAIN: Epoch 19/41, loss_G_GAN   -0.0108, loss_G_L1    2.4137, loss_G    2.4029, loss_D_GAN   -0.0000, loss_D    0.0024\n","06/11/2020 04:33:40 - INFO - __main__ -   VALID: Batch 0/63, loss_G_GAN   -0.0084, loss_G_L1    2.4523, loss_G    2.4439, loss_D_GAN    0.0400, loss_D    0.0400\n","06/11/2020 04:33:48 - INFO - __main__ -   VALID: Batch 10/63, loss_G_GAN   -0.0076, loss_G_L1    2.3769, loss_G    2.3692, loss_D_GAN    0.0062, loss_D    0.0062\n","06/11/2020 04:33:52 - INFO - __main__ -   VALID: Epoch 19/41, loss_G_GAN   -0.0074, loss_G_L1    2.6736, loss_G    2.6661, loss_D_GAN    0.0055, loss_D    0.0055\n","06/11/2020 04:33:54 - INFO - __main__ -   TRAIN: Batch 0/63, loss_G_GAN   -0.0055, loss_G_L1    2.4924, loss_G    2.4869, loss_D_GAN    0.0000, loss_D    0.0026\n","06/11/2020 04:34:22 - INFO - __main__ -   TRAIN: Batch 10/63, loss_G_GAN   -0.0118, loss_G_L1    2.1271, loss_G    2.1154, loss_D_GAN    0.0000, loss_D    0.0039\n","06/11/2020 04:34:50 - INFO - __main__ -   TRAIN: Batch 20/63, loss_G_GAN   -0.0084, loss_G_L1    2.0680, loss_G    2.0596, loss_D_GAN   -0.0000, loss_D    0.0016\n","06/11/2020 04:35:18 - INFO - __main__ -   TRAIN: Batch 30/63, loss_G_GAN   -0.0077, loss_G_L1    1.7791, loss_G    1.7714, loss_D_GAN   -0.0000, loss_D    0.0007\n","06/11/2020 04:35:46 - INFO - __main__ -   TRAIN: Batch 40/63, loss_G_GAN   -0.0102, loss_G_L1    2.5218, loss_G    2.5116, loss_D_GAN    0.0000, loss_D    0.0000\n","06/11/2020 04:36:14 - INFO - __main__ -   TRAIN: Batch 50/63, loss_G_GAN   -0.0108, loss_G_L1    2.0826, loss_G    2.0717, loss_D_GAN   -0.0000, loss_D    0.0003\n","06/11/2020 04:36:42 - INFO - __main__ -   TRAIN: Batch 60/63, loss_G_GAN   -0.0179, loss_G_L1    2.6826, loss_G    2.6647, loss_D_GAN   -0.0000, loss_D    0.0007\n","06/11/2020 04:36:50 - INFO - __main__ -   TRAIN: Epoch 20/41, loss_G_GAN   -0.0119, loss_G_L1    2.2316, loss_G    2.2197, loss_D_GAN    0.0000, loss_D    0.0023\n","06/11/2020 04:36:51 - INFO - root -   Summary name FAKE TRAIN epoch 20 ~ min: 0.000000 max: 0.000000 is illegal; using FAKE_TRAIN_epoch_20___min__0.000000_max__0.000000 instead.\n","06/11/2020 04:36:51 - WARNING - root -   NaN or Inf found in input tensor.\n","06/11/2020 04:36:51 - INFO - root -   Summary name REAL TRAIN epoch 20 ~ min: 0.000000 max: 0.114038 is illegal; using REAL_TRAIN_epoch_20___min__0.000000_max__0.114038 instead.\n","06/11/2020 04:36:53 - INFO - __main__ -   VALID: Batch 0/63, loss_G_GAN   -0.0152, loss_G_L1    2.5415, loss_G    2.5263, loss_D_GAN    0.0011, loss_D    0.0011\n","06/11/2020 04:37:01 - INFO - __main__ -   VALID: Batch 10/63, loss_G_GAN   -0.0150, loss_G_L1    2.3976, loss_G    2.3826, loss_D_GAN    0.0050, loss_D    0.0051\n","06/11/2020 04:37:05 - INFO - __main__ -   VALID: Epoch 20/41, loss_G_GAN   -0.0147, loss_G_L1    2.2965, loss_G    2.2818, loss_D_GAN    0.0067, loss_D    0.0067\n","06/11/2020 04:37:05 - INFO - root -   Summary name FAKE VALID epoch 20 ~ min: 0.000000 max: 0.000000 is illegal; using FAKE_VALID_epoch_20___min__0.000000_max__0.000000 instead.\n","06/11/2020 04:37:05 - WARNING - root -   NaN or Inf found in input tensor.\n","06/11/2020 04:37:05 - INFO - root -   Summary name REAL VALID epoch 20 ~ min: 0.000000 max: 0.112303 is illegal; using REAL_VALID_epoch_20___min__0.000000_max__0.112303 instead.\n","06/11/2020 04:37:08 - INFO - __main__ -   TRAIN: Batch 0/63, loss_G_GAN   -0.0150, loss_G_L1    2.1949, loss_G    2.1800, loss_D_GAN    0.0000, loss_D    0.0001\n","06/11/2020 04:37:36 - INFO - __main__ -   TRAIN: Batch 10/63, loss_G_GAN   -0.0184, loss_G_L1    2.1908, loss_G    2.1725, loss_D_GAN   -0.0000, loss_D    0.0002\n","06/11/2020 04:38:04 - INFO - __main__ -   TRAIN: Batch 20/63, loss_G_GAN   -0.0152, loss_G_L1    1.6261, loss_G    1.6109, loss_D_GAN    0.0000, loss_D    0.0002\n","06/11/2020 04:38:32 - INFO - __main__ -   TRAIN: Batch 30/63, loss_G_GAN   -0.0094, loss_G_L1    2.3264, loss_G    2.3170, loss_D_GAN    0.0000, loss_D    0.0034\n","06/11/2020 04:39:00 - INFO - __main__ -   TRAIN: Batch 40/63, loss_G_GAN   -0.0062, loss_G_L1    2.2185, loss_G    2.2123, loss_D_GAN    0.0000, loss_D    0.0090\n","06/11/2020 04:39:28 - INFO - __main__ -   TRAIN: Batch 50/63, loss_G_GAN    0.0017, loss_G_L1    2.4919, loss_G    2.4937, loss_D_GAN   -0.0000, loss_D    0.0001\n","06/11/2020 04:39:56 - INFO - __main__ -   TRAIN: Batch 60/63, loss_G_GAN   -0.0139, loss_G_L1    2.3711, loss_G    2.3572, loss_D_GAN   -0.0000, loss_D    0.0008\n","06/11/2020 04:40:04 - INFO - __main__ -   TRAIN: Epoch 21/41, loss_G_GAN   -0.0131, loss_G_L1    2.1327, loss_G    2.1196, loss_D_GAN    0.0000, loss_D    0.0023\n","06/11/2020 04:40:05 - INFO - __main__ -   VALID: Batch 0/63, loss_G_GAN   -0.0148, loss_G_L1    1.8262, loss_G    1.8114, loss_D_GAN    0.0008, loss_D    0.0008\n","06/11/2020 04:40:13 - INFO - __main__ -   VALID: Batch 10/63, loss_G_GAN   -0.0149, loss_G_L1    1.8807, loss_G    1.8658, loss_D_GAN    0.0000, loss_D    0.0000\n","06/11/2020 04:40:17 - INFO - __main__ -   VALID: Epoch 21/41, loss_G_GAN   -0.0146, loss_G_L1    2.0813, loss_G    2.0668, loss_D_GAN    0.0095, loss_D    0.0095\n","06/11/2020 04:40:20 - INFO - __main__ -   TRAIN: Batch 0/63, loss_G_GAN   -0.0155, loss_G_L1    1.7913, loss_G    1.7758, loss_D_GAN   -0.0000, loss_D    0.0003\n","06/11/2020 04:40:48 - INFO - __main__ -   TRAIN: Batch 10/63, loss_G_GAN   -0.0164, loss_G_L1    1.8612, loss_G    1.8448, loss_D_GAN   -0.0000, loss_D    0.0002\n","06/11/2020 04:41:16 - INFO - __main__ -   TRAIN: Batch 20/63, loss_G_GAN   -0.0144, loss_G_L1    2.3893, loss_G    2.3749, loss_D_GAN   -0.0000, loss_D    0.0009\n","Traceback (most recent call last):\n","  File \"train.py\", line 271, in <module>\n","    train(generator, discriminator, train_dl, valid_dl, 41)\n","  File \"train.py\", line 163, in train\n","    loss_D_t, loss_D_GAN_t = train_discriminator(fake, fake_source, real)\n","  File \"train.py\", line 83, in train_discriminator\n","    return float(loss_D.item()) + float(grad_penalty.item()), float(loss_D.item())\n","KeyboardInterrupt\n"],"name":"stdout"}]}]}